{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0. Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pyproj import Proj, transform\n",
    "from haversine import haversine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"C:\\\\Users\\\\SOHYEUN\\\\Desktop\\\\BOAZ_광진구\\\\광진구_최종\\\\\"\n",
    "\n",
    "center = pd.read_csv(path + \"center.csv\")\n",
    "park = pd.read_csv(path + \"park.csv\", encoding='cp949')\n",
    "bus = pd.read_csv(path + \"bus.csv\", encoding='cp949')\n",
    "subway = pd.read_excel(path + \"subway.xlsx\")\n",
    "tow = pd.read_csv(path + \"tow.csv\", encoding='cp949')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the center of the hexagon by averaging the left-right and bottom-top values\n",
    "center['X'] = (center['left'] + center['right']) / 2\n",
    "center['Y'] = (center['bottom'] + center['top']) / 2\n",
    "center.drop(columns=['left', 'right', 'bottom', 'top', '최종_레이블_결과(2)_행정동', '최종_레이블_결과(2)_클러스터링', \n",
    "                     '최종_레이블_결과(2)_유동인구', '최종_레이블_결과(2)_견인횟수', '최종_레이블_결과(2)_유동인구_레이블', '최종_레이블_결과(2)_견인횟수_레이블'], inplace=True)\n",
    "center.dropna(inplace=True)\n",
    "center.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Coordinate transformation (UTM-K to WGS84)\n",
    "original_crs = Proj(init='epsg:5179')  # UTM-K\n",
    "target_crs = Proj(init='epsg:4326')  # WGS84\n",
    "\n",
    "def convert_coordinates(x, y):\n",
    "    lon, lat = transform(original_crs, target_crs, x, y)\n",
    "    return lat, lon\n",
    "\n",
    "center['경도'], center['위도'] = zip(*center.apply(lambda row: convert_coordinates(row['X'], row['Y']), axis=1))\n",
    "center.drop(columns=['row_index', 'col_index', 'X', 'Y'], inplace=True)\n",
    "center.rename(columns={'최종_레이블_결과(2)_유동인구+견인횟수': '유동인구+견인횟수', '위도': '경도', '경도': '위도'}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare location points for different datasets\n",
    "center_points = np.array([list(i) for i in zip(center['위도'], center['경도'])])\n",
    "bus_points = np.array([list(i) for i in zip(bus['위도'], bus['경도'])])\n",
    "subway_points = np.array([list(i) for i in zip(subway['위도'], subway['경도'])])\n",
    "park_points = np.array([list(i) for i in zip(park['위도'], park['경도'])])\n",
    "tow_points = np.array([list(i) for i in zip(tow['위도'], tow['경도'])])\n",
    "\n",
    "# Combine all location points\n",
    "X = list(bus['경도']) + list(subway['경도']) + list(park['경도']) + list(tow['경도'])\n",
    "Y = list(bus['위도']) + list(subway['위도']) + list(park['위도']) + list(tow['위도'])\n",
    "points = np.array([list(i) for i in zip(X, Y)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate weights for balancing data distribution\n",
    "total_w = points.shape[0]\n",
    "bus_w = bus_points.shape[0]\n",
    "subway_w = subway_points.shape[0]\n",
    "park_w = park_points.shape[0]\n",
    "tow_w = tow_points.shape[0]\n",
    "\n",
    "m1 = (total_w - bus_w) / total_w\n",
    "m2 = (total_w - subway_w) / total_w\n",
    "m3 = (total_w - park_w) / total_w\n",
    "m4 = (total_w - tow_w) / total_w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define p-median function to calculate distance weights\n",
    "def pmedian(center_points, bus_points, subway_points, park_points, tow_points):\n",
    "    # Calculate distances for each location type\n",
    "    def calculate_distances(center_points, points):\n",
    "        return [[haversine(i, j) * 1000 for j in points] for i in center_points]\n",
    "\n",
    "    # Calculate weighted distance matrices for each point type\n",
    "    havers1 = calculate_distances(center_points, bus_points)\n",
    "    havers2 = calculate_distances(center_points, subway_points)\n",
    "    havers3 = calculate_distances(center_points, park_points)\n",
    "    havers4 = calculate_distances(center_points, tow_points)\n",
    "\n",
    "    # Create DataFrames for each location's distance matrix\n",
    "    location = list(center['id'])\n",
    "    location1 = list(bus['정류소명'])\n",
    "    location2 = list(subway['역명'])\n",
    "    location3 = list(park['주차장명'])\n",
    "    location4 = list(tow['주소'])\n",
    "\n",
    "    havers_D1 = dict(zip(location, [dict(zip(location1, i)) for i in havers1]))\n",
    "    havers_D2 = dict(zip(location, [dict(zip(location2, i)) for i in havers2]))\n",
    "    havers_D3 = dict(zip(location, [dict(zip(location3, i)) for i in havers3]))\n",
    "    havers_D4 = dict(zip(location, [dict(zip(location4, i)) for i in havers4]))\n",
    "\n",
    "    # Convert distance matrices to DataFrames\n",
    "    D1 = pd.DataFrame(havers_D1)\n",
    "    D2 = pd.DataFrame(havers_D2)\n",
    "    D3 = pd.DataFrame(havers_D3)\n",
    "    D4 = pd.DataFrame(havers_D4)\n",
    "\n",
    "    # Assign weights based on minimum distance\n",
    "    def assign_weights(D, min_values, weight):\n",
    "        for i in D.index:\n",
    "            for j in D.columns:\n",
    "                D.loc[i, j] = weight if D.loc[i, j] == min_values[i] else 0\n",
    "        return D\n",
    "\n",
    "    bus_min = D1.min(axis=1)\n",
    "    subway_min = D2.min(axis=1)\n",
    "    park_min = D3.min(axis=1)\n",
    "    tow_min = D4.min(axis=1)\n",
    "\n",
    "    D1 = assign_weights(D1, bus_min, m1)\n",
    "    D2 = assign_weights(D2, subway_min, m2)\n",
    "    D3 = assign_weights(D3, park_min, m3)\n",
    "    D4 = assign_weights(D4, tow_min, m4)\n",
    "\n",
    "    # Combine all DataFrames\n",
    "    D_final = pd.concat([D1, D2, D3, D4])\n",
    "\n",
    "    return D_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "D_final = pmedian(center_points, bus_points, subway_points, park_points, tow_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summarize results and save to CSV\n",
    "result_df = pd.DataFrame(D_final.sum().sort_values(ascending=False), columns=['Weight'])\n",
    "result_df.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top 30 locations by weight\n",
    "result_df_30 = result_df[:30]\n",
    "result_df_30.to_csv(path + \"P-median_30.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
